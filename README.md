
# ğŸš€ Employee Attrition Prediction ML Pipeline

This project implements an **end-to-end MLOps pipeline** for predicting employee attrition. It includes steps for data loading, preprocessing, feature engineering, model training, evaluation, and experiment tracking using **MLflow**. The pipeline can be executed either **locally using Python** or inside **Docker containers using Docker Compose**.

---

## ğŸ“š Table of Contents

- [âœ¨ Features](#-features)
- [ğŸ“ Project Structure](#-project-structure)
- [ğŸ› ï¸ Prerequisites](#ï¸-prerequisites)
- [âš™ï¸ Setup](#ï¸-setup)
  - [1. Clone Repository](#1-clone-repository)
  - [2. Prepare Data](#2-prepare-data)
  - [3. Python Environment (for Local Execution)](#3-python-environment-for-local-execution)
- [ğŸš¦ Running the Pipeline](#-running-the-pipeline)
  - [Option 1: Using Docker (Recommended)](#option-1-using-docker-recommended)
  - [Option 2: Running Locally with Python Orchestrator](#option-2-running-locally-with-python-orchestrator)
- [ğŸ” Pipeline Steps](#-pipeline-steps)
- [ğŸ“¦ Outputs](#-outputs)
- [ğŸ Troubleshooting](#-troubleshooting)

---

## âœ¨ Features

- ğŸ”„ **Data Loading & Preprocessing**  
- ğŸ”€ **Train/Test Splitting**  
- ğŸ§ª **Feature Engineering** (e.g., scaling, encoding)  
- ğŸ¤– **Model Training & Evaluation** (Logistic Regression, Random Forest)  
- ğŸ“Š **MLflow Experiment Tracking**  
- ğŸ³ **Dockerized Execution**  
- ğŸ **Python-Based Orchestration**  

---

## ğŸ“ Project Structure

.
â”œâ”€â”€ data
â”‚ â”œâ”€â”€ raw/ # Input raw data (e.g., employee_attrition.csv)
â”‚ â””â”€â”€ processed/ # Processed data (splits, transformed data)
â”œâ”€â”€ models/ # Trained models and preprocessors
â”œâ”€â”€ mlruns/ # MLflow tracking data
â”œâ”€â”€ scripts/
â”‚ â””â”€â”€ run_training.sh # Bash script for Docker-based execution
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ data/
â”‚ â”‚ â”œâ”€â”€ load_data.py # Load and preprocess data
â”‚ â”‚ â””â”€â”€ split.py # Data splitting
â”‚ â”œâ”€â”€ features/
â”‚ â”‚ â””â”€â”€ build_features.py # Feature engineering
â”‚ â”œâ”€â”€ models/
â”‚ â”‚ â””â”€â”€ train_model.py # Train and evaluate model
â”‚ â””â”€â”€ init.py
â”œâ”€â”€ .gitignore
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ run_pipeline.py # Local orchestrator
â””â”€â”€ README.md # This file

yaml
Copy
Edit

---

## ğŸ› ï¸ Prerequisites

- **Git**
- **Docker & Docker Compose**
- **Python 3.8+**
- **pip**
- **Raw Dataset:** Place `employee_attrition.csv` into `data/raw/`.

---

## âš™ï¸ Setup

### 1. Clone Repository

```bash
git clone <your-repository-url>
cd <your-repository-name>
2. Prepare Data
bash
Copy
Edit
mkdir -p data/raw
Place your employee_attrition.csv file into data/raw/.

3. Python Environment (for Local Execution)
bash
Copy
Edit
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
Create and populate requirements.txt:

txt
Copy
Edit
# requirements.txt
pandas
scikit-learn
joblib
mlflow
numpy
matplotlib
seaborn
Then install dependencies:

bash
Copy
Edit
pip install -r requirements.txt
ğŸš¦ Running the Pipeline
âœ… Option 1: Using Docker (Recommended)
ğŸ”§ Build and Run Pipeline
bash
Copy
Edit
docker-compose build run-pipeline
docker-compose up run-pipeline
Or build all services:

bash
Copy
Edit
docker-compose build
docker-compose up run-pipeline
ğŸŒ Access MLflow UI (Docker)
bash
Copy
Edit
docker-compose up mlflow-ui
Navigate to http://localhost:5001 to view experiment logs.

ğŸ Option 2: Running Locally with Python Orchestrator
â–¶ï¸ Run Pipeline Script
bash
Copy
Edit
source venv/bin/activate
python run_pipeline.py
ğŸŒ Access MLflow UI (Local)
bash
Copy
Edit
mlflow ui
Navigate to http://localhost:5000 to explore runs and metrics.

ğŸ” Pipeline Steps
Load and Preprocess Data

Input: data/raw/employee_attrition.csv

Output: processed_employee_attrition.csv

Split Data

Output: train.csv, test.csv

Build Features

Output: X_train_processed.csv, X_test_processed.csv, y_train.csv, y_test.csv

Artifacts: preprocessor.joblib

Train and Evaluate Model

Output: model.joblib

Logs: Parameters, metrics, plots (e.g., ROC, confusion matrix)

ğŸ“¦ Outputs
data/processed/

processed_employee_attrition.csv

train.csv, test.csv

X_train_processed.csv, X_test_processed.csv

y_train.csv, y_test.csv

models/

preprocessor.joblib

model.joblib

mlruns/

MLflow experiments, parameters, metrics, and artifacts

ğŸ Troubleshooting
FileNotFoundError for employee_attrition.csv:
Ensure it's located in data/raw/.

Docker Volume Permission Issues (Linux):

bash
Copy
Edit
sudo chown -R $(id -u):$(id -g) data models mlruns
Port Conflicts (5000 or 5001):
Update ports in docker-compose.yml or use:

bash
Copy
Edit
mlflow ui --port 5050
Module Not Found (Local):

Activate your environment.

Run from the project root.

Ensure correct PYTHONPATH.

Module Not Found (Docker):
Dockerfile sets PYTHONPATH=/app. Ensure youâ€™re using python -m from project root.

ğŸ“Œ Note: Replace placeholders like <your-repository-url> and <your-repository-name> before committing.

âœ… To-Do Before Commit
âœ… Add a complete requirements.txt

âœ… Place employee_attrition.csv in data/raw/

âœ… Add .gitignore to exclude:

venv/, __pycache__/, *.pyc

data/processed/, models/, mlruns/ (unless intentional)
Behrooz Filzadeh

Happy ML Ops-ing! ğŸš€









